"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[17756],{15680:(e,t,n)=>{n.d(t,{xA:()=>u,yg:()=>g});var a=n(96540);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),c=p(n),m=o,g=c["".concat(s,".").concat(m)]||c[m]||d[m]||r;return n?a.createElement(g,i(i({ref:t},u),{},{components:n})):a.createElement(g,i({ref:t},u))}));function g(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[c]="string"==typeof e?e:o,i[1]=l;for(var p=2;p<r;p++)i[p]=n[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},97266:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var a=n(58168),o=(n(96540),n(15680));const r={description:"Deploy Riva and Llama2 on reComputer",title:"Finetune with Llama-Factory",keywords:["reComputer","LLM","Chatbot","Finetune"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/Finetune_LLM_on_Jetson",last_update:{date:"07/03/2024",author:"Youjiang"}},i="Custom Local LLM: Fine-tune LLM by Llama-Factory on Jetson",l={unversionedId:"Edge/NVIDIA_Jetson/Application/Generative_AI/Finetune_LLM_by_Llama_Factory_on_Jetson",id:"Edge/NVIDIA_Jetson/Application/Generative_AI/Finetune_LLM_by_Llama_Factory_on_Jetson",title:"Finetune with Llama-Factory",description:"Deploy Riva and Llama2 on reComputer",source:"@site/docs/Edge/NVIDIA_Jetson/Application/Generative_AI/Finetune_LLM_by_Llama_Factory_on_Jetson.md",sourceDirName:"Edge/NVIDIA_Jetson/Application/Generative_AI",slug:"/Finetune_LLM_on_Jetson",permalink:"/Finetune_LLM_on_Jetson",draft:!1,editUrl:"https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Edge/NVIDIA_Jetson/Application/Generative_AI/Finetune_LLM_by_Llama_Factory_on_Jetson.md",tags:[],version:"current",lastUpdatedBy:"Youjiang",lastUpdatedAt:1719964800,formattedLastUpdatedAt:"Jul 3, 2024",frontMatter:{description:"Deploy Riva and Llama2 on reComputer",title:"Finetune with Llama-Factory",keywords:["reComputer","LLM","Chatbot","Finetune"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/Finetune_LLM_on_Jetson",last_update:{date:"07/03/2024",author:"Youjiang"}},sidebar:"ProductSidebar",previous:{title:"Generative AI with reComputer-Jetson\xae",permalink:"/Generative_AI_Intro"},next:{title:"Faster Inference with MLC",permalink:"/Quantized_Llama2_7B_with_MLC_LLM_on_Jetson"}},s={},p=[{value:"Introduction",id:"introduction",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Getting Started",id:"getting-started",level:2},{value:"Hardware Connection",id:"hardware-connection",level:3},{value:"Install Jetson-Examples",id:"install-jetson-examples",level:3},{value:"Install and Run Llama-Factory on Jetson",id:"install-and-run-llama-factory-on-jetson",level:3},{value:"Start Training",id:"start-training",level:3},{value:"Testing the Fine-tuned Model.",id:"testing-the-fine-tuned-model",level:3},{value:"Demonstration",id:"demonstration",level:3},{value:"References",id:"references",level:2},{value:"Tech Support &amp; Product Discussion",id:"tech-support--product-discussion",level:2}],u={toc:p},c="wrapper";function d(e){let{components:t,...n}=e;return(0,o.yg)(c,(0,a.A)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("h1",{id:"custom-local-llm-fine-tune-llm-by-llama-factory-on-jetson"},"Custom Local LLM: Fine-tune LLM by Llama-Factory on Jetson"),(0,o.yg)("h2",{id:"introduction"},"Introduction"),(0,o.yg)("p",null,"\ud83d\ude80Finetune LLM by Llama-Factory on Jetson! Now you can tailor a custom private local LLM to meet your requirements. "),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer-Jetson/Llama-Factory/run.gif"})),(0,o.yg)("p",null,"Llama-Factory provides a highly convenient large language model fine-tuning tool that supports common large language models, datasets, and fine-tuning methods. With this platform, we can easily customize private large language models."),(0,o.yg)("p",null,"In this wiki, we will learn how to deploy Llama-Factory on Nvidia Jetson and use Llama-Factory to train a large language model that supports Chinese Q&A."),(0,o.yg)("h2",{id:"prerequisites"},"Prerequisites"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Jetson device with more than 16GB of memory."),(0,o.yg)("li",{parentName:"ul"},"Monitor, mouse, keyboard and network. (not necessary)")),(0,o.yg)("admonition",{type:"note"},(0,o.yg)("p",{parentName:"admonition"},"We have already tested the feasibility of this wiki on reComputer ",(0,o.yg)("a",{parentName:"p",href:"https://www.seeedstudio.com/reComputer-J4012-p-5586.html"},"Orin NX 16GB")," and ",(0,o.yg)("a",{parentName:"p",href:"https://www.seeedstudio.com/NVIDIArJetson-AGX-Orintm-64GB-Developer-Kit-p-5641.html"},"AGX Orin 64GB")," Developer Kit.")),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer-Jetson/Llama-Factory/agx_orin.png"})),(0,o.yg)("div",{class:"get_one_now_container",style:{textAlign:"center"}},(0,o.yg)("a",{class:"get_one_now_item",href:"https://www.seeedstudio.com/AGX-Orin-32GB-H01-Kit-p-5569.html?queryID=a07376a957f072a4f755e1832fa0e544&objectID=5569&indexName=bazaar_retailer_products"},(0,o.yg)("strong",null,(0,o.yg)("span",null,(0,o.yg)("font",{color:"FFFFFF",size:"4"}," Get One Now \ud83d\uddb1\ufe0f"))))),(0,o.yg)("h2",{id:"getting-started"},"Getting Started"),(0,o.yg)("h3",{id:"hardware-connection"},"Hardware Connection"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},"Connect the Ethernet cable to the reComputer (Powered by Jetson)."),(0,o.yg)("li",{parentName:"ol"},"Connect the mouse, keyboard, and monitor to the reComputer."),(0,o.yg)("li",{parentName:"ol"},"Power on reComputer.")),(0,o.yg)("h3",{id:"install-jetson-examples"},"Install Jetson-Examples"),(0,o.yg)("admonition",{type:"note"},(0,o.yg)("p",{parentName:"admonition"},"The ",(0,o.yg)("a",{parentName:"p",href:"https://github.com/Seeed-Projects/jetson-examples"},"jetson-examples")," by Seeed Studio offers a seamless, one-line command deployment to run vision AI and Generative AI models on the NVIDIA Jetson platform.")),(0,o.yg)("p",null,"To install the package, please open the terminal in Jetson and run:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"pip3 install jetson-examples\nsudo reboot\n")),(0,o.yg)("h3",{id:"install-and-run-llama-factory-on-jetson"},"Install and Run Llama-Factory on Jetson"),(0,o.yg)("p",null,"Deploy ",(0,o.yg)("inlineCode",{parentName:"p"},"Llama-Factory")," by jetson-examples in one-line:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"reComputer run llama-factory\n")),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer-Jetson/Llama-Factory/run_llama_factory.png"})),(0,o.yg)("p",null,"We can then open a web browser and access the address to open the WebUI:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"# http://<jetson-ip>:7860\nhttp://127.0.0.1:7860\n")),(0,o.yg)("h3",{id:"start-training"},"Start Training"),(0,o.yg)("p",null,"Here, we use the ",(0,o.yg)("inlineCode",{parentName:"p"},"alpaca_zh")," dataset to fine-tune the ",(0,o.yg)("inlineCode",{parentName:"p"},"Phi-1.5")," model, enabling it to have Chinese conversational capabilities. Therefore, in the web UI, we only configure the training ",(0,o.yg)("inlineCode",{parentName:"p"},"Model name")," and ",(0,o.yg)("inlineCode",{parentName:"p"},"Dataset"),", keeping the other training parameters as default. "),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer-Jetson/Llama-Factory/run_train.png"})),(0,o.yg)("p",null,"Finally, click the ",(0,o.yg)("inlineCode",{parentName:"p"},"start")," button to initiate the training."),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer-Jetson/Llama-Factory/training.png"})),(0,o.yg)("admonition",{type:"note"},(0,o.yg)("p",{parentName:"admonition"},"The training process will take approximately 18 hours.")),(0,o.yg)("p",null,"After completing the fine-tuning, you can find the fine-tuned model in the save directory."),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer-Jetson/Llama-Factory/train_result.png"})),(0,o.yg)("h3",{id:"testing-the-fine-tuned-model"},"Testing the Fine-tuned Model."),(0,o.yg)("p",null,"Finally, we can use Llama-Factory with the fine-tuned model to test if it indeed has acquired Chinese conversational capabilities. The specific steps are as follows."),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step1.")," Load the fine-tuned model by Llama-Factory WebUI."),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer-Jetson/Llama-Factory/load_model.png"})),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step2.")," Enter a Chinese prompt in the ",(0,o.yg)("inlineCode",{parentName:"p"},"Input")," text box, click the ",(0,o.yg)("inlineCode",{parentName:"p"},"Submit")," button, and check the output result of the large language model in the ",(0,o.yg)("inlineCode",{parentName:"p"},"Chatbot")," text box."),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer-Jetson/Llama-Factory/test_model.png"})),(0,o.yg)("p",null,"From the test results, we can see that the fine-tuned model already has the capability to talk with human in Chinese. If you want your model to have more advanced capabilities, try using a more diverse set of fine-tuning data to train your model!"),(0,o.yg)("h3",{id:"demonstration"},"Demonstration"),(0,o.yg)("div",{align:"center"},(0,o.yg)("iframe",{width:"800",height:"450",src:"https://www.youtube.com/embed/OaGEn7pVve0",title:"Finetune LLM by Llama-Factory on Jetson",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:!0})),(0,o.yg)("h2",{id:"references"},"References"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"https://github.com/hiyouga/LLaMA-Factory"},"https://github.com/hiyouga/LLaMA-Factory")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"https://github.com/dusty-nv/jetson-containers/tree/cb6c847f88df221e705397a1ee98424c2e893243/packages/llm/text-generation-inference"},"https://github.com/dusty-nv/jetson-containers")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"https://github.com/Seeed-Projects/jetson-examples/tree/main/reComputer/scripts/llama-factory"},"https://github.com/Seeed-Projects/jetson-examples"))),(0,o.yg)("h2",{id:"tech-support--product-discussion"},"Tech Support & Product Discussion"),(0,o.yg)("p",null,"Thank you for choosing our products! We are here to provide you with different support to ensure that your experience with our products is as smooth as possible. We offer several communication channels to cater to different preferences and needs."),(0,o.yg)("div",{class:"button_tech_support_container"},(0,o.yg)("a",{href:"https://forum.seeedstudio.com/",class:"button_forum"}),(0,o.yg)("a",{href:"https://www.seeedstudio.com/contacts",class:"button_email"})),(0,o.yg)("div",{class:"button_tech_support_container"},(0,o.yg)("a",{href:"https://discord.gg/eWkprNDMU7",class:"button_discord"}),(0,o.yg)("a",{href:"https://github.com/Seeed-Studio/wiki-documents/discussions/69",class:"button_discussion"})))}d.isMDXComponent=!0}}]);