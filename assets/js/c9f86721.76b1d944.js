"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[74227],{15680:(e,t,n)=>{n.d(t,{xA:()=>p,yg:()=>m});var a=n(96540);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function r(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),d=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=d(e.components);return a.createElement(s.Provider,{value:t},e.children)},c="mdxType",g={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,s=e.parentName,p=r(e,["components","mdxType","originalType","parentName"]),c=d(n),h=o,m=c["".concat(s,".").concat(h)]||c[h]||g[h]||i;return n?a.createElement(m,l(l({ref:t},p),{},{components:n})):a.createElement(m,l({ref:t},p))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,l=new Array(i);l[0]=h;var r={};for(var s in t)hasOwnProperty.call(t,s)&&(r[s]=t[s]);r.originalType=e,r[c]="string"==typeof e?e:o,l[1]=r;for(var d=2;d<i;d++)l[d]=n[d];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},21317:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>g,frontMatter:()=>i,metadata:()=>r,toc:()=>d});var a=n(58168),o=(n(96540),n(15680));const i={description:"This wiki will demonstrate how to set up a local knowledge base on Jetson devices with ollama and AnythingLLM. By leveraging the powerful capabilities of large language models, we aim to enhance our work efficiency.",title:"Local AI Assistant",keywords:["reComputer","LLM","Chatbot","ollama","AnythingLLM","llama"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/local_ai_ssistant",last_update:{date:"07/30/2024",author:"Youjiang"}},l="Local AI Assistant : Deploy Ollama and AnytingLLM on Jetson",r={unversionedId:"Edge/NVIDIA_Jetson/Application/Generative_AI/Deploy_Ollama_and_AnythingLLM_on_Jetson",id:"Edge/NVIDIA_Jetson/Application/Generative_AI/Deploy_Ollama_and_AnythingLLM_on_Jetson",title:"Local AI Assistant",description:"This wiki will demonstrate how to set up a local knowledge base on Jetson devices with ollama and AnythingLLM. By leveraging the powerful capabilities of large language models, we aim to enhance our work efficiency.",source:"@site/docs/Edge/NVIDIA_Jetson/Application/Generative_AI/Deploy_Ollama_and_AnythingLLM_on_Jetson.md",sourceDirName:"Edge/NVIDIA_Jetson/Application/Generative_AI",slug:"/local_ai_ssistant",permalink:"/local_ai_ssistant",draft:!1,editUrl:"https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Edge/NVIDIA_Jetson/Application/Generative_AI/Deploy_Ollama_and_AnythingLLM_on_Jetson.md",tags:[],version:"current",lastUpdatedBy:"Youjiang",lastUpdatedAt:1722297600,formattedLastUpdatedAt:"Jul 30, 2024",frontMatter:{description:"This wiki will demonstrate how to set up a local knowledge base on Jetson devices with ollama and AnythingLLM. By leveraging the powerful capabilities of large language models, we aim to enhance our work efficiency.",title:"Local AI Assistant",keywords:["reComputer","LLM","Chatbot","ollama","AnythingLLM","llama"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/local_ai_ssistant",last_update:{date:"07/30/2024",author:"Youjiang"}},sidebar:"ProductSidebar",previous:{title:"Real Time Subtitle Recoder",permalink:"/Real Time Subtitle Recoder on Nvidia Jetson"},next:{title:"Install ROS1",permalink:"/installing_ros1"}},s={},d=[{value:"Introduction",id:"introduction",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Getting Started",id:"getting-started",level:2},{value:"Hardware Connection",id:"hardware-connection",level:3},{value:"Install and Run Ollama",id:"install-and-run-ollama",level:3},{value:"Install and Run AnythingLLM",id:"install-and-run-anythingllm",level:3},{value:"Let&#39;s Run It",id:"lets-run-it",level:3},{value:"Effect Demonstration",id:"effect-demonstration",level:2},{value:"References",id:"references",level:2},{value:"Tech Support &amp; Product Discussion",id:"tech-support--product-discussion",level:2}],p={toc:d},c="wrapper";function g(e){let{components:t,...n}=e;return(0,o.yg)(c,(0,a.A)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("h1",{id:"local-ai-assistant--deploy-ollama-and-anytingllm-on-jetson"},"Local AI Assistant : Deploy Ollama and AnytingLLM on Jetson"),(0,o.yg)("h2",{id:"introduction"},"Introduction"),(0,o.yg)("p",null,"Local AI Assistant is an artificial intelligence application that runs on local hardware and software, offering intelligent interaction and data processing capabilities. It operates independently of cloud services, protecting user privacy while providing quick response times and high levels of customization. "),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/local-ai-assistant/ai-assistant.png"})),(0,o.yg)("p",null,"In this wiki, we will demonstrate how to set up a local knowledge base on Jetson devices with ",(0,o.yg)("a",{parentName:"p",href:"https://ollama.com/"},"ollama")," and ",(0,o.yg)("a",{parentName:"p",href:"https://anythingllm.com/"},"AnythingLLM"),". By leveraging the powerful capabilities of large language models, we aim to enhance our work efficiency."),(0,o.yg)("h2",{id:"prerequisites"},"Prerequisites"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Jetson device with more than 16GB of memory."),(0,o.yg)("li",{parentName:"ul"},"The hardware device needs to be pre-flashed with the jetpack ",(0,o.yg)("a",{parentName:"li",href:"https://wiki.seeedstudio.com/reComputer_Intro/"},"5.1.1")," operating system.")),(0,o.yg)("admonition",{type:"note"},(0,o.yg)("p",{parentName:"admonition"},"In this wiki, we will accomplish the following tasks using the ",(0,o.yg)("a",{parentName:"p",href:"https://www.seeedstudio.com/NVIDIArJetson-AGX-Orintm-64GB-Developer-Kit-p-5641.html"},"NVIDIA\xae Jetson AGX Orin\u2122 64GB Developer Kit"),", but you can also try using other Jetson devices.")),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/local-ai-assistant/AGX-Orin.png"})),(0,o.yg)("div",{class:"get_one_now_container",style:{textAlign:"center"}},(0,o.yg)("a",{class:"get_one_now_item",href:"https://www.seeedstudio.com/AGX-Orin-32GB-H01-Kit-p-5569.html?queryID=a07376a957f072a4f755e1832fa0e544&objectID=5569&indexName=bazaar_retailer_products"},(0,o.yg)("strong",null,(0,o.yg)("span",null,(0,o.yg)("font",{color:"FFFFFF",size:"4"}," Get One Now \ud83d\uddb1\ufe0f"))))),(0,o.yg)("h2",{id:"getting-started"},"Getting Started"),(0,o.yg)("h3",{id:"hardware-connection"},"Hardware Connection"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Connect the Jetson device to the network, mouse, keyboard, and monitor.")),(0,o.yg)("admonition",{type:"note"},(0,o.yg)("p",{parentName:"admonition"},"Of course, you can also remotely access the Jetson device via SSH over the local network.")),(0,o.yg)("h3",{id:"install-and-run-ollama"},"Install and Run Ollama"),(0,o.yg)("p",null,"Here, we highly recommend using ",(0,o.yg)("a",{parentName:"p",href:"https://github.com/Seeed-Projects/jetson-examples"},"jetson-examples")," to quickly deploy Ollama on your Jetson device."),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step1.")," Open a terminal on jetson device and run the following command to install ",(0,o.yg)("inlineCode",{parentName:"p"},"jetson-examples"),":"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"sudo apt install python3-pip\npip3 install jetson-examples\n")),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step2.")," To deploy ollama on Jetson device with a single command, we can run:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"reComputer run ollama\n")),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step3.")," Download the Llama3 large model using Ollama:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"ollama run llama3\n")),(0,o.yg)("admonition",{type:"info"},(0,o.yg)("p",{parentName:"admonition"},"Please keep this terminal active.")),(0,o.yg)("h3",{id:"install-and-run-anythingllm"},"Install and Run AnythingLLM"),(0,o.yg)("p",null,"We can conveniently install AnythingLLM using a ",(0,o.yg)("a",{parentName:"p",href:"https://docs.anythingllm.com/installation/self-hosted/local-docker#recommend-way-to-run-dockerized-anythingllm"},"local Docker setup"),"."),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step1.")," Run AnythingLLM on Jetson."),(0,o.yg)("p",null,"Reopen the terminal and enter the following command:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},'docker pull mintplexlabs/anythingllm\n\nexport STORAGE_LOCATION=$HOME/anythingllm \nmkdir -p $STORAGE_LOCATION \ntouch "$STORAGE_LOCATION/.env" \ndocker run -d -p 3001:3001 --cap-add SYS_ADMIN \\\n    -v ${STORAGE_LOCATION}:/app/server/storage \\\n    -v ${STORAGE_LOCATION}/.env:/app/server/.env \\\n    -e STORAGE_DIR="/app/server/storage" \\\n    mintplexlabs/anythingllm\n')),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step2.")," Configure your own local knowledge base."),(0,o.yg)("p",null,"To access the full application, visit ",(0,o.yg)("inlineCode",{parentName:"p"},"http://<jetson-ip>:3001")," in your browser."),(0,o.yg)("admonition",{type:"note"},(0,o.yg)("p",{parentName:"admonition"},"You can enter the ",(0,o.yg)("inlineCode",{parentName:"p"},"ifconfig")," command on the Jetson terminal to find its IP address.")),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/local-ai-assistant/anythingllm-init.png"})),(0,o.yg)("p",null,"Follow the on-screen prompts to complete the configuration of AnythingLLM."),(0,o.yg)("admonition",{type:"danger"},(0,o.yg)("p",{parentName:"admonition"},"Please note that on the configuration page of ",(0,o.yg)("inlineCode",{parentName:"p"},"LLM Perference"),", we should select Ollama's Llama 3.1 large language model.")),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/local-ai-assistant/select-ollama.png"})),(0,o.yg)("p",null,"Finally, import the necessary documents. The large language model will then answer questions based on the imported documents."),(0,o.yg)("p",null,(0,o.yg)("inlineCode",{parentName:"p"},"import")," --\x3e ",(0,o.yg)("inlineCode",{parentName:"p"},"click to upload or drag and drop")," --\x3e ",(0,o.yg)("inlineCode",{parentName:"p"},"select document")," --\x3e ",(0,o.yg)("inlineCode",{parentName:"p"},"move to Workspace")," --\x3e ",(0,o.yg)("inlineCode",{parentName:"p"},"save and embed")),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/local-ai-assistant/inport-doc.png"})),(0,o.yg)("p",null,"At this point, you have successfully set up your own local knowledge base."),(0,o.yg)("admonition",{type:"note"},(0,o.yg)("p",{parentName:"admonition"},"For more in-depth configuration tutorials, please refer to ",(0,o.yg)("a",{parentName:"p",href:"https://docs.anythingllm.com/"},"this link"),".")),(0,o.yg)("h3",{id:"lets-run-it"},"Let's Run It"),(0,o.yg)("p",null,"Enter questions in the dialogue box, and the large language model will provide answers based on the knowledge base."),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/local-ai-assistant/test.png"})),(0,o.yg)("details",null,(0,o.yg)("summary",null," story1.txt "),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-txt"},"Once upon a time in a quaint village nestled between rolling hills, there was a young girl named Eliza who loved to explore the woods behind her home. The forest was a magical place, filled with tall trees that whispered secrets, streams that sang soft melodies, and flowers that seemed to glow under the moonlight.\n\nOne sunny morning, Eliza set out on one of her adventures, her heart brimming with excitement. As she wandered deeper into the forest, she discovered a hidden path she had never seen before. The path was lined with shimmering stones that sparkled like stars. Curious and intrigued, Eliza followed it.\n\nAfter a short walk, the path led her to a magnificent clearing where a majestic oak tree stood in the center. At the base of the tree was a small, ornate door. It was covered in intricate carvings of animals and vines. Eliza, with her heart pounding with both excitement and nervousness, gently pushed the door open.\n\nInside, she found herself in a cozy, enchanted room. There were shelves lined with books and strange artifacts, and a warm fire crackling in a stone hearth. In the middle of the room, a wise old owl perched on a branch of a large, leafy plant.\n\nThe owl looked at Eliza with kind, knowing eyes. \u201cWelcome, young traveler,\u201d it hooted softly. \u201cI am Oliver, the guardian of this magical realm. Few people find their way here. You must have a special heart.\u201d\n\nEliza\u2019s eyes widened in awe. \u201cWhat is this place?\u201d she asked.\n\n\u201cThis is the Realm of Wonders,\u201d Oliver explained. \u201cIt is a place where dreams come to life and where those with pure intentions can find their heart\u2019s true desire.\u201d\n\nEliza gazed around the room, her curiosity piqued. \u201cWhat can I do here?\u201d\n\nOliver smiled. \u201cYou can make a wish. But remember, wishes made here come with great responsibility. They have the power to change not just your life but the lives of those around you.\u201d\n\nEliza thought long and hard. She remembered how her village had been struggling with drought and how her friends and family were suffering. With a determined look, she made her wish.\n\n\u201cI wish for rain to fall upon my village and bring life back to the land.\u201d\n\nOliver nodded approvingly. \u201cA selfless wish. It will be granted.\u201d\n\nThe next morning, as Eliza returned to her village, dark clouds gathered in the sky, and a gentle rain began to fall. The villagers looked up in amazement as the parched earth drank in the life-giving water. The fields began to turn green, and the village flourished once more.\n\nEliza\u2019s heart swelled with joy as she realized the impact of her wish. The Realm of Wonders had given her the chance to make a difference, and she learned that true magic comes from caring for others.\n\nFrom that day on, Eliza continued to explore the woods, knowing that the true wonders of life were found in kindness and selflessness.\n\nAnd so, the village thrived, and Eliza\u2019s adventures became the stuff of legends, reminding everyone that magic, indeed, begins with a kind heart.\n"))),(0,o.yg)("h2",{id:"effect-demonstration"},"Effect Demonstration"),(0,o.yg)("p",null,"Here, we use the configured local personal assistant to query the information we need."),(0,o.yg)("div",{align:"center"},(0,o.yg)("iframe",{width:"800",height:"450",src:"https://www.youtube.com/embed/JjPfXNqhO1g",title:"Local AI Assistant : Deploy Ollama and AnytingLLM on Jetson",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:!0})),(0,o.yg)("h2",{id:"references"},"References"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"https://ollama.com/library/llama3.1"},"https://ollama.com/library/llama3.1")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"https://anythingllm.com/"},"https://anythingllm.com/")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=4UFrVvy7VlA&t=4s"},"https://www.youtube.com/watch?v=4UFrVvy7VlA&t=4s"))),(0,o.yg)("h2",{id:"tech-support--product-discussion"},"Tech Support & Product Discussion"),(0,o.yg)("p",null,"Thank you for choosing our products! We are here to provide you with different support to ensure that your experience with our products is as smooth as possible. We offer several communication channels to cater to different preferences and needs."),(0,o.yg)("div",{class:"button_tech_support_container"},(0,o.yg)("a",{href:"https://forum.seeedstudio.com/",class:"button_forum"}),(0,o.yg)("a",{href:"https://www.seeedstudio.com/contacts",class:"button_email"})),(0,o.yg)("div",{class:"button_tech_support_container"},(0,o.yg)("a",{href:"https://discord.gg/eWkprNDMU7",class:"button_discord"}),(0,o.yg)("a",{href:"https://github.com/Seeed-Studio/wiki-documents/discussions/69",class:"button_discussion"})))}g.isMDXComponent=!0}}]);