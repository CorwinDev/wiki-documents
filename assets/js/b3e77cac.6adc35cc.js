"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[66064],{15680:(e,t,n)=>{n.d(t,{xA:()=>u,yg:()=>g});var r=n(96540);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=r.createContext({}),p=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=p(e.components);return r.createElement(l.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=p(n),m=o,g=c["".concat(l,".").concat(m)]||c[m]||d[m]||a;return n?r.createElement(g,i(i({ref:t},u),{},{components:n})):r.createElement(g,i({ref:t},u))}));function g(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,i=new Array(a);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:o,i[1]=s;for(var p=2;p<a;p++)i[p]=n[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},70872:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>s,toc:()=>p});var r=n(58168),o=(n(96540),n(15680));const a={description:"This wiki provides a tutorial on how to run VLM on reComputer Jetson.",title:"How to Run VLM on reComputer",keywords:["reComputer","VLM"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/run_vlm_on_recomputer",last_update:{date:"7/24/2024",author:"ZhuYaoHui"}},i="How to Run VLM on reComputer with Jetson Platform Services",s={unversionedId:"Edge/NVIDIA_Jetson/Application/Generative_AI/How_to_run_VLM_on_reComputer",id:"Edge/NVIDIA_Jetson/Application/Generative_AI/How_to_run_VLM_on_reComputer",title:"How to Run VLM on reComputer",description:"This wiki provides a tutorial on how to run VLM on reComputer Jetson.",source:"@site/docs/Edge/NVIDIA_Jetson/Application/Generative_AI/How_to_run_VLM_on_reComputer.md",sourceDirName:"Edge/NVIDIA_Jetson/Application/Generative_AI",slug:"/run_vlm_on_recomputer",permalink:"/run_vlm_on_recomputer",draft:!1,editUrl:"https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Edge/NVIDIA_Jetson/Application/Generative_AI/How_to_run_VLM_on_reComputer.md",tags:[],version:"current",lastUpdatedBy:"ZhuYaoHui",lastUpdatedAt:1721779200,formattedLastUpdatedAt:"Jul 24, 2024",frontMatter:{description:"This wiki provides a tutorial on how to run VLM on reComputer Jetson.",title:"How to Run VLM on reComputer",keywords:["reComputer","VLM"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/run_vlm_on_recomputer",last_update:{date:"7/24/2024",author:"ZhuYaoHui"}},sidebar:"ProductSidebar",previous:{title:"How to Run Zero-Shot Detection on reComputer",permalink:"/run_zero_shot_detection_on_recomputer"},next:{title:"Format Output with Langchain",permalink:"/How_to_Format_the_Output_of_LLM_Using_Langchain_on_Jetson"}},l={},p=[{value:"Introduction",id:"introduction",level:2},{value:"Requirements",id:"requirements",level:2},{value:"Getting Started",id:"getting-started",level:2},{value:"Add the RTSP stream input",id:"add-the-rtsp-stream-input",level:2},{value:"Set Alerts",id:"set-alerts",level:2},{value:"View RTSP Stream Result",id:"view-rtsp-stream-result",level:2},{value:"Shut Down",id:"shut-down",level:2},{value:"More Details",id:"more-details",level:2},{value:"Tech Support &amp; Product Discussion",id:"tech-support--product-discussion",level:2}],u={toc:p},c="wrapper";function d(e){let{components:t,...n}=e;return(0,o.yg)(c,(0,r.A)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("h1",{id:"how-to-run-vlm-on-recomputer-with-jetson-platform-services"},"How to Run VLM on reComputer with Jetson Platform Services"),(0,o.yg)("h2",{id:"introduction"},"Introduction"),(0,o.yg)("p",null,"vision language models (VLMs) are multi modal models supporting images, video and text and using a combination of large language models and vision transformers. Based on this capability, they are able to support text prompts to query videos and images thereby enabling capabilities such as chatting with the video, and defining natural language based alerts. The ",(0,o.yg)("a",{parentName:"p",href:"https://docs.nvidia.com/jetson/jps/inference-services/vlm.html"},"VLM AI service"),", enables quick deployment of VLMs with Jetson Platform Services for video insight applications. The VLM service exposes REST API endpoints to configure the video stream input, set alerts and ask questions in natural language about the input video stream."),(0,o.yg)("p",null,"This wiki provides a tutorial on how to run VLM on ",(0,o.yg)("a",{parentName:"p",href:"https://www.seeedstudio.com/reComputer-J4012-p-5586.html"},"reComputer J4012 Jetson Orin NX"),"."),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:900,src:"https://files.seeedstudio.com/wiki/reComputer/Application/vlm/vlmgif.gif"})),(0,o.yg)("h2",{id:"requirements"},"Requirements"),(0,o.yg)("p",null,"Before proceeding with the setup process, please ensure that your system meets the following prerequisites:"),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer-Jetson/Llama-Factory/agx_orin.png"})),(0,o.yg)("div",{class:"get_one_now_container",style:{textAlign:"center"}},(0,o.yg)("a",{class:"get_one_now_item",href:"https://www.seeedstudio.com/AGX-Orin-32GB-H01-Kit-p-5569.html?queryID=a07376a957f072a4f755e1832fa0e544&objectID=5569&indexName=bazaar_retailer_products"},(0,o.yg)("strong",null,(0,o.yg)("span",null,(0,o.yg)("font",{color:"FFFFFF",size:"4"}," Get One Now \ud83d\uddb1\ufe0f"))))),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"A reComputer J4012 Orin NX 16G running Ubuntu ",(0,o.yg)("inlineCode",{parentName:"li"},"22.04")," or ",(0,o.yg)("inlineCode",{parentName:"li"},"later"),"."),(0,o.yg)("li",{parentName:"ul"},"Driver Version: ",(0,o.yg)("inlineCode",{parentName:"li"},"535.113.01"),", Jetpack ",(0,o.yg)("inlineCode",{parentName:"li"},"6.0")," and CUDA Version: ",(0,o.yg)("inlineCode",{parentName:"li"},"12.2"),"."),(0,o.yg)("li",{parentName:"ul"},"Make sure that JetPack and the related Jetson services packages are installed.",(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"sudo apt-get install nvidia-jetpack\nsudo apt install nvidia-jetson-services\n"))),(0,o.yg)("li",{parentName:"ul"},"IP cameras or local videos can be streamed via RTSP. (We recommend using our provided ",(0,o.yg)("a",{parentName:"li",href:"/getting_started_with_nvstreamer"},"NVStreamer tutorial")," for RTSP streaming.)")),(0,o.yg)("h2",{id:"getting-started"},"Getting Started"),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 1"),": Download the application package ",(0,o.yg)("strong",{parentName:"p"},(0,o.yg)("inlineCode",{parentName:"strong"},"vlm-1.1.0.tar.gz"))," from NGC to your Jetson using this link: ",(0,o.yg)("a",{parentName:"p",href:"https://catalog.ngc.nvidia.com/orgs/nvidia/teams/jps/resources/reference-workflow-and-resources"},"NGC Reference Workflow and Resources"),". You will need to enter your NGC credentials. On the page, use one of the options available in the ",(0,o.yg)("strong",{parentName:"p"},(0,o.yg)("inlineCode",{parentName:"strong"},"Download"))," menu (top right corner):"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"tar -xvf vlm-1.1.0.tar.gz\ncd ~/vlm/example_1\n")),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 2"),": The VLM AI service will use the ",(0,o.yg)("inlineCode",{parentName:"p"},"jetson-ingress")," and ",(0,o.yg)("inlineCode",{parentName:"p"},"jetson-monitoring")," services. You need to configure these two services to integrate with the VLM AI service. Copy the provided default configuration to the corresponding service configuration directory:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"sudo cp config/vlm-nginx.conf /opt/nvidia/jetson/services/ingress/config\nsudo cp config/prometheus.yml /opt/nvidia/jetson/services/monitoring/config/prometheus.yml\nsudo cp config/rules.yml /opt/nvidia/jetson/services/monitoring/config/rules.yml\n")),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 3"),": Run the basic services:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"sudo systemctl start jetson-ingress\nsudo systemctl start jetson-monitoring\nsudo systemctl start jetson-sys-monitoring\nsudo systemctl start jetson-gpu-monitoring\nsudo systemctl start jetson-redis\nsudo systemctl start jetson-vst\n")),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 4"),": When starting the VLM service for the first time, it will automatically download and quantize the VLM. This process may take some time. If deploying on Orin NX16, you might need to mount more SWAP space because the quantization process can consume a large amount of memory. Run the following commands to mount more swap space:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"sudo fallocate -l 10G /data/10GB.swap\nsudo mkswap /data/10GB.swap\nsudo swapon /data/10GB.swap\n")),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 5"),": Start the VLM AI service:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"cd ~/vlm/example_1\nsudo docker compose up -d\n")),(0,o.yg)("p",null,"To check if all required containers have started, you can run the following command:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"sudo docker ps\n")),(0,o.yg)("div",{align:"center"},(0,o.yg)("img",{width:1e3,src:"https://files.seeedstudio.com/wiki/reComputer/Application/vlm/vlmfig2.png"})),(0,o.yg)("h2",{id:"add-the-rtsp-stream-input"},"Add the RTSP stream input"),(0,o.yg)("p",null,"You can first add an RTSP stream for the VLM model to use with the following curl command. It is recommended to use the ",(0,o.yg)("a",{parentName:"p",href:"/getting_started_with_nvstreamer"},"NVStreamer tutorial")," for streaming."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("p",{parentName:"li"},(0,o.yg)("strong",{parentName:"p"},"Step 1"),": Replace ",(0,o.yg)("inlineCode",{parentName:"p"},"0.0.0.0")," with your Jetson IP and the ",(0,o.yg)("inlineCode",{parentName:"p"},"liveStreamUrl")," link with your RTSP link, then enter the following command in the terminal:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"curl --location 'http://0.0.0.0:5010/api/v1/live-stream' \\\n--header 'Content-Type: application/json' \\\n--data '{\n\"liveStreamUrl\": \"rtsp://0.0.0.0:31554/nvstream/root/store/nvstreamer_videos/car.mp4\"\n}'\n")),(0,o.yg)("p",{parentName:"li"},"  Note: Besides the curl command, you can also directly test the REST API through the API documentation page, which is available at ",(0,o.yg)("inlineCode",{parentName:"p"},"http://0.0.0.0:5010/docs")," when the zero-shot detection service is started. ")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("p",{parentName:"li"},(0,o.yg)("strong",{parentName:"p"},"Step 2"),": After executing the first step, an ID will be returned. You need to record this ID for use in subsequent steps:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-bash"},'{"id": "a782e200-eb48-4d17-a1b9-5ac0696217f7"}\n')),(0,o.yg)("p",{parentName:"li"},"  You can also obtain the ID later using the following command:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"curl --location 'http://0.0.0.0:5010/api/v1/live-stream'\n")),(0,o.yg)("p",{parentName:"li"},"  To delete a stream by its ID, you can use the following command:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"curl --location --request DELETE 'http://0.0.0.0:5010/api/v1/live-stream/{id}'\n")))),(0,o.yg)("h2",{id:"set-alerts"},"Set Alerts"),(0,o.yg)("p",null,"Alerts are questions that the VLM will continuously evaluate on the live stream input. For each alert rule set, the VLM will try to decide if it is True or False based on the most recent frame from of the live stream. These True and False states as determined by the VLM, are sent to a websocket and the jetson monitoring service."),(0,o.yg)("p",null,"When setting alerts, the alert rule should be phrased as a yes/no question. Such as \u201cIs there fire?\u201d or \u201cIs there smoke?\u201d. The body of the request must also have the \u201cid\u201d field that corresponds to the stream ID that was returned when the RTSP stream was added."),(0,o.yg)("p",null,"By default, the VLM service supports up to 10 alert rules. This can be increased by adjusting the configuration files."),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Step 1"),": Replace ",(0,o.yg)("inlineCode",{parentName:"p"},"0.0.0.0")," with your reComputer IP address, modify ",(0,o.yg)("inlineCode",{parentName:"p"},"alerts")," to include the objects you need to alerts, use the ",(0,o.yg)("inlineCode",{parentName:"p"},"id")," returned in the previous step. After completing the command, enter the following in the terminal:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},'curl --location \'http://0.0.0.0:5010/api/v1/alerts\' \\\n--header \'Content-Type: application/json\' \\\n--data \'{\n    "alerts": ["is there a fire?", "is there smoke?"],\n    "id": "a782e200-eb48-4d17-a1b9-5ac0696217f7"\n}\'\n')),(0,o.yg)("h2",{id:"view-rtsp-stream-result"},"View RTSP Stream Result"),(0,o.yg)("p",null,"The detection output will be streamed through ",(0,o.yg)("inlineCode",{parentName:"p"},"rtsp://reComputer_ip:5011/out"),". We provide a Python script for visualizing the video stream output, You need to install the opencv-python library in advance and then run the following Python script:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Step 1:")," Install the opencv-python library:",(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"pip install opencv-python\n"))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Step 2:")," Run the following Python script:",(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-python"},'import cv2\nrtsp_url = "rtsp://reComputer_ip:5011/out"\ncap = cv2.VideoCapture(rtsp_url)\nif not cap.isOpened():\n    print("Cannot open RTSP stream")\n    exit()\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        print("Failed to retrieve frame")\n        break\n    cv2.imshow(\'RTSP Stream\', frame)\n    if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n        break\ncap.release()\ncv2.destroyAllWindows()\n')))),(0,o.yg)("h2",{id:"shut-down"},"Shut Down"),(0,o.yg)("p",null,"To stop the zero-shot detection service, run the following command in the same directory where the ",(0,o.yg)("inlineCode",{parentName:"p"},"compose.yaml")," file is located:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"sudo docker compose down\n")),(0,o.yg)("h2",{id:"more-details"},"More Details"),(0,o.yg)("p",null,"Visual Language Models (VLM) with Jetson Platform Services: ",(0,o.yg)("a",{parentName:"p",href:"https://docs.nvidia.com/jetson/jps/inference-services/vlm.html"},"https://docs.nvidia.com/jetson/jps/inference-services/vlm.html")),(0,o.yg)("h2",{id:"tech-support--product-discussion"},"Tech Support & Product Discussion"),(0,o.yg)("p",null,"Thank you for choosing our products! We are here to provide you with different support to ensure that your experience with our products is as smooth as possible. We offer several communication channels to cater to different preferences and needs."),(0,o.yg)("div",{class:"button_tech_support_container"},(0,o.yg)("a",{href:"https://forum.seeedstudio.com/",class:"button_forum"}),(0,o.yg)("a",{href:"https://www.seeedstudio.com/contacts",class:"button_email"})),(0,o.yg)("div",{class:"button_tech_support_container"},(0,o.yg)("a",{href:"https://discord.gg/eWkprNDMU7",class:"button_discord"}),(0,o.yg)("a",{href:"https://github.com/Seeed-Studio/wiki-documents/discussions/69",class:"button_discussion"})))}d.isMDXComponent=!0}}]);